---
title: "Something Interesting Baseball"
author: "Jozi McKiernan, Sean O'Keeffe & Sam Woodman"
output: pdf_document
header-includes:
  - \usepackage{graphicx}
bibliography: report.bib
nocite: |
  @ggplot2, @shiny, @dplyr, @RCurl, @jsonlite, @shinydashboard, @RgoogleMaps, @xml, @tidyr, @mosaic, @stringr, @R
---

[//]: # Introduction Section-------------------------------------------------
# Introduction

[//]: # Data Collection Section----------------------------------------------
# Data Collection
The data collection for this project was the most involved component.
We were able to find comprehensive statistics for any given player from @stats, however each page was for one player.
So we had to go find a list of all players for a given year.
We found this from @players.
Now that we had all the predicting attributes, we still needed to know if a player was traded.
All transactions for a given a month for a given year was found through @trades.
However, there are instances of teams changing names and some entries from @trades, include minor league teams so we also needed a list of all the major league baseball teams and their naming history.
In this section, we will discuss some of the subtleties that made this a difficult process.

To keep our project organized, we split up the data collection into their own files. So we run all the data collection here and we will have code bits to describe some of the steps. Refer to the `final_project.R` file and all the other supplemental files.
```{r, message=FALSE, eval=FALSE}
setwd("~/Documents/GitHub/MATH154_FinalProject")
source("final_project.R", local=TRUE, echo=FALSE)
```

## List of all players

## Player statistics

## Teams
The list of team names were acquired manually, there are only 30 teams so it was very manageable.
We also got data on the location of every team.
Although a location is given in the team name, situations like the *Florida Marlins* is not an easy thing to locate on a map.
These locations were also acquired manually.
Team colors were also recorded manually.
Lastly, we also wanted latitude and longitude locations for each team.
This data came from google maps, using a package in R called `Rgooglemaps` from @RgoogleMaps.
For each of the city locations, we look up the lat lon data with an API call to Google Maps.

The data looks like
```{r, eval=FALSE}
head(teams, n = 3)
```

## Trades
The trade data was a unique problem that we hadn't seen before.
When you try to scrape the HTML code for this website as we have done previously, no tables appear.
It turns out that the tables are generated on the client side through Java script so scraping the initial request doesn't give you anything. 
However the data itself had to be sent at some point, so after digging through some of the other files transfered, we found a JSON file that seemed to contain all the data we wanted.
So we query the URL for this file rather than the website.
```{r, eval=FALSE}
# This website loads the table data using Javascript. We go directly to the 
# JSON file which provides the data.
url <- paste('http://mlb.mlb.com/lookup/json/named.transaction_all.bam?start_date=',
             start_date,
             '&end_date=',
             end_date,
             '&sport_code=%27mlb%27',
             sep='')
json <- getURL(url)
tempData <- as.data.frame(fromJSON(json))
```
From here we trim down the data so that we only keep the data we're interested in.
```{r, eval=FALSE}
# Filter all the things we don't want. 
tempData <- tempData %>%
  # Only want trades
  filter(transaction_all.queryResults.row.type_cd=='TR') %>% 
  # Only want certain columns
  select(transaction_all.queryResults.row.team, 
         transaction_all.queryResults.row.from_team, 
         transaction_all.queryResults.row.player) %>% 
  # Remove any empty rows
  filter(transaction_all.queryResults.row.player != '') %>% 
  # Add a year attribute
  mutate(Year = year) %>% 
  # Add a key to match with stats data
  mutate(MatchKey = paste(transaction_all.queryResults.row.player, Year)) 
```

We do these steps for all 12 months during 2010 to 2015.
This ultimately gives us a table that is shown below, see .
```{r, eval=FALSE}
head(trades, n = 3)
```

[//]: # Classification Section-----------------------------------------------
# Classification

[//]: # Shiny Web App Section------------------------------------------------
# Shiny Web App
The Shiny Web App has 3 tabs, Predict Trades, Trades Map, and a Single Variable Trend.
Each one of these tabs will be described below.

## Predict Trades
We built a classifier using statistics of the baseball players to try and predict wether or not a player would get traded.
In this tab you can input statistics on any hitter or batter.
Then the app will magically run that point through our classifier and predict wether or not that player would get traded given those statistics.

## Trades Map
This is a graphic that let's you visualize the trades.
As you can see in Figure~\ref{fig:trades_map}, you can select any number of teams you want and then the map will have on it all the trades that happened during 2010 to 2015 to the selected teams.
Below that is a data dump of those trades.
This doesn't tell us anything particularly useful about the data, it was just a fun visualization.

\begin{figure}
\centering
\includegraphics[width=0.6\textwidth]{trades_map.png}
\label{fig:trades_map}
\caption{Screenshot of Trades Map tab.}
\end{figure}

## Single Variable Trend
This tab allows you to select one of the predictor variables for batters or pitchers and see it's effects on a player getting traded.
The output is a plot that shows for which values of the selected variable, the players in our data got traded.
Using this, you can get a better understanding of which variables might be important and which ones are irrelevant.
If there was a strong connection between any single variable and a players likelihood to be traded, it would be present in these graphs.

\newpage
